"""
Test Chunking Strategy - Kiá»ƒm tra hoáº¡t Ä‘á»™ng cá»§a chunking tá»‘i Æ°u
"""

import sys
from pathlib import Path
import time

current_file = Path(__file__)
aiservice_dir = current_file.parents[2]
src_dir = aiservice_dir / "src"
sys.path.insert(0, str(src_dir))

# Import trá»±c tiáº¿p tá»« src
sys.path.insert(0, str(src_dir / "rag"))

try:
    from src.features.rag.chunking import (
        Chunking,
        ChunkingConfig,
        MultilingualTextProcessor,
        chunk_text,
        chunk_documents,
    )
    from langchain_core.documents import Document
except ImportError:
    # Fallback import
    sys.path.insert(0, str(aiservice_dir))
    from src.features.rag.chunking import (
        Chunking,
        ChunkingConfig,
        MultilingualTextProcessor,
        chunk_text,
        chunk_documents,
    )
    from langchain_core.documents import Document


def test_multilingual_text_processor():
    """Test MultilingualTextProcessor"""
    print("\nTest MultilingualTextProcessor")
    print("-" * 30)

    processor = MultilingualTextProcessor()
    print("   Khá»Ÿi táº¡o MultilingualTextProcessor thÃ nh cÃ´ng!")

    # Test phÃ¡t hiá»‡n ngÃ´n ngá»¯
    print("\n   Test phÃ¡t hiá»‡n ngÃ´n ngá»¯:")
    test_cases = [
        ("Xin chÃ o, tÃ´i lÃ  trá»£ lÃ½ AI", "vietnamese"),
        ("Hello, I am an AI assistant", "english"),
        ("TÃ´i speak English vÃ  tiáº¿ng Viá»‡t", "mixed"),
        ("123 456 789", "unknown"),
        ("Viá»‡t Nam Ä‘ang phÃ¡t triá»ƒn máº¡nh máº½", "vietnamese"),
        ("Machine learning is the future", "english"),
    ]

    for text, expected in test_cases:
        result = processor.detect_language(text)
        status = "PASS" if result["language"] == expected else "FAIL"
        print(f"   {status}: '{text[:30]}...'")
        print(f"      â†’ PhÃ¡t hiá»‡n: {result['language']} (Dá»± kiáº¿n: {expected})")
        print(
            f"      â†’ Tá»· lá»‡ VN: {result['vietnamese_ratio']:.2f}, Tin cáº­y: {result['confidence']:.2f}"
        )

    # Test phÃ¢n tÃ­ch cáº¥u trÃºc
    print("\n   Test phÃ¢n tÃ­ch cáº¥u trÃºc:")
    structure_tests = [
        ("ÄÃ¢y lÃ  vÄƒn báº£n Ä‘Æ¡n giáº£n khÃ´ng cÃ³ cáº¥u trÃºc Ä‘áº·c biá»‡t.", "simple"),
        ("CHÆ¯Æ NG 1: Tá»”NG QUAN\n\nNá»™i dung chÆ°Æ¡ng 1", "hierarchical"),
        ("# Heading 1\n## Heading 2\n### Heading 3", "hierarchical"),
        ("```python\ndef hello():\n    print('hello')\n```", "code"),
        ("| Cá»™t 1 | Cá»™t 2 | Cá»™t 3 |\n|-------|-------|-------|", "tabular"),
    ]

    for text, expected in structure_tests:
        analysis = processor.analyze_structure(text)
        status = "PASS" if analysis["structure_type"] == expected else "FAIL"
        print(f"   {status}: '{text[:30]}...'")
        print(f"      â†’ Cáº¥u trÃºc: {analysis['structure_type']} (Dá»± kiáº¿n: {expected})")
        print(
            f"      â†’ Headings: {analysis['has_headings']}, Lists: {analysis['has_lists']}"
        )
        print(f"      â†’ Tables: {analysis['has_tables']}, Code: {analysis['has_code']}")

    # Test trÃ­ch xuáº¥t cáº¥u trÃºc phÃ¢n cáº¥p
    print("\n   Test trÃ­ch xuáº¥t cáº¥u trÃºc phÃ¢n cáº¥p:")
    hierarchical_text = """
CHÆ¯Æ NG I: GIá»šI THIá»†U

Ná»™i dung giá»›i thiá»‡u

PHáº¦N 1: Äá»ŠA LÃ

1.1 Vá»‹ trÃ­ Ä‘á»‹a lÃ½
Ná»™i dung Ä‘á»‹a lÃ½

1.2 KhÃ­ háº­u
Ná»™i dung khÃ­ háº­u

PHáº¦N 2: DÃ‚N CÆ¯

2.1 DÃ¢n sá»‘
Ná»™i dung dÃ¢n sá»‘
"""

    hierarchy = processor.extract_hierarchical_structure(hierarchical_text)
    print(f"   PhÃ¡t hiá»‡n {len(hierarchy)} headings:")
    for h in hierarchy:
        print(f"      DÃ²ng {h['line_number']}: Level {h['level']} - '{h['text']}'")
    print("   Test trÃ­ch xuáº¥t cáº¥u trÃºc hoÃ n thÃ nh")


def test_chunking_class():
    """Test class Chunking"""
    print("\nTest class Chunking")
    print("-" * 30)

    # Test khá»Ÿi táº¡o vá»›i config máº·c Ä‘á»‹nh
    chunker = Chunking()
    print("   Khá»Ÿi táº¡o Chunking vá»›i config máº·c Ä‘á»‹nh thÃ nh cÃ´ng!")
    print(f"   Chunk size: {chunker.config.chunk_size}")
    print(f"   Chunk overlap: {chunker.config.chunk_overlap}")

    # Test khá»Ÿi táº¡o vá»›i config tÃ¹y chá»‰nh
    custom_config = ChunkingConfig(chunk_size=256, chunk_overlap=32)
    custom_chunker = Chunking(custom_config)
    print(
        f"   Chunker tÃ¹y chá»‰nh - Size: {custom_chunker.config.chunk_size}, Overlap: {custom_chunker.config.chunk_overlap}"
    )

    # Test Ä‘áº¿m tokens
    print("\n   Test Ä‘áº¿m tokens:")
    test_texts = [
        ("VÄƒn báº£n tiáº¿ng Viá»‡t cÃ³ dáº¥u", "vietnamese"),
        ("English text without diacritics", "english"),
        ("Mixed vÄƒn báº£n with English", "mixed"),
    ]

    for text, lang_type in test_texts:
        tokens = chunker._count_tokens(text)
        chars = len(text)
        ratio = chars / tokens if tokens > 0 else 0
        print(
            f"   {lang_type}: '{text}' â†’ {tokens} tokens ({chars} chars, tá»· lá»‡: {ratio:.1f})"
        )


def test_chunking_strategies():
    """Test cÃ¡c strategies chunking"""
    print("\nTest Chunking Strategies")
    print("-" * 30)

    chunker = Chunking()

    # Test 1: Simple chunking
    print("\n   Test Simple Chunking:")
    simple_text = """
ÄÃ¢y lÃ  má»™t Ä‘oáº¡n vÄƒn báº£n Ä‘Æ¡n giáº£n Ä‘á»ƒ test chunking.
NÃ³ khÃ´ng cÃ³ cáº¥u trÃºc phá»©c táº¡p hay tiÃªu Ä‘á» Ä‘áº·c biá»‡t.
Chá»‰ lÃ  vÄƒn báº£n thÃ´ng thÆ°á»ng vá»›i nhiá»u cÃ¢u.
Má»¥c Ä‘Ã­ch lÃ  kiá»ƒm tra xem chunker cÃ³ hoáº¡t Ä‘á»™ng Ä‘Ãºng khÃ´ng.
"""
    chunks = chunker.chunk_text(simple_text)
    print(f"   Input: {len(simple_text)} kÃ½ tá»±")
    print(f"   Output: {len(chunks)} chunks")
    if chunks:
        print(f"   Strategy: {chunks[0].metadata.get('strategy')}")
        print(f"   Sample: '{chunks[0].page_content[:50]}...'")

    # Test 2: Hierarchical chunking
    print("\n   Test Hierarchical Chunking:")
    hierarchical_text = """
CHÆ¯Æ NG I: Tá»”NG QUAN Vá»€ VIá»†T NAM

Viá»‡t Nam lÃ  má»™t quá»‘c gia náº±m á»Ÿ ÄÃ´ng Nam Ã vá»›i diá»‡n tÃ­ch 331.000 kmÂ².

PHáº¦N 1: Äá»ŠA LÃ VÃ€ KHÃ“I Háº¬U

1.1 Vá»‹ trÃ­ Ä‘á»‹a lÃ½
Viá»‡t Nam náº±m á»Ÿ phÃ­a Ä‘Ã´ng bÃ¡n Ä‘áº£o ÄÃ´ng DÆ°Æ¡ng, giÃ¡p vá»›i Trung Quá»‘c á»Ÿ phÃ­a báº¯c.

1.2 KhÃ­ háº­u
Viá»‡t Nam cÃ³ khÃ­ háº­u nhiá»‡t Ä‘á»›i giÃ³ mÃ¹a vá»›i hai mÃ¹a chÃ­nh.

PHáº¦N 2: DÃ‚N CÆ¯ VÃ€ XÃƒ Há»˜I

2.1 DÃ¢n sá»‘ vÃ  cáº¥u trÃºc
Viá»‡t Nam cÃ³ dÃ¢n sá»‘ khoáº£ng 97 triá»‡u ngÆ°á»i.

2.2 VÄƒn hÃ³a vÃ  truyá»n thá»‘ng
VÄƒn hÃ³a Viá»‡t Nam Ä‘a dáº¡ng vÃ  phong phÃº.
"""
    chunks = chunker.chunk_text(hierarchical_text)
    print(f"   Input: {len(hierarchical_text)} kÃ½ tá»±")
    print(f"   Output: {len(chunks)} chunks")
    if chunks:
        print(f"   Strategy: {chunks[0].metadata.get('strategy')}")
        for i, chunk in enumerate(chunks):
            section_level = chunk.metadata.get("section_level", "N/A")
            print(
                f"   Chunk {i+1}: Level {section_level} - '{chunk.page_content[:40]}...'"
            )

    # Test 3: Mixed language content
    print("\n   Test Mixed Language Chunking:")
    mixed_text = """
# Vietnam Technology Overview

Vietnam Ä‘ang trá»Ÿ thÃ nh má»™t trong nhá»¯ng trung tÃ¢m cÃ´ng nghá»‡ hÃ ng Ä‘áº§u á»Ÿ ÄÃ´ng Nam Ã. 
The country has experienced rapid digital transformation in recent years.

## Key Sectors

### Software Development
Viá»‡t Nam cÃ³ hÆ¡n 500,000 láº­p trÃ¬nh viÃªn. Many international companies have 
established development centers here.

### E-commerce Growth  
Thá»‹ trÆ°á»ng thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ tÄƒng trÆ°á»Ÿng 25% má»—i nÄƒm. Major platforms include 
Shopee, Tiki, and Lazada.

## Challenges and Opportunities

While Vietnam has made significant progress, challenges remain:
- Thiáº¿u há»¥t nhÃ¢n lá»±c cháº¥t lÆ°á»£ng cao
- Infrastructure development needs
- Regulatory framework improvements
"""
    chunks = chunker.chunk_text(mixed_text)
    print(f"   Input: {len(mixed_text)} kÃ½ tá»±")
    print(f"   Output: {len(chunks)} chunks")
    if chunks:
        print(f"   Strategy: {chunks[0].metadata.get('strategy')}")
        lang_info = (
            chunks[0].metadata.get("structure_analysis", {}).get("language_info", {})
        )
        print(
            f"   Language: {lang_info.get('language')}, Confidence: {lang_info.get('confidence', 0):.2f}"
        )


def test_simple_api():
    """Test API Ä‘Æ¡n giáº£n"""
    print("\nTest Simple API")
    print("-" * 30)

    # Test function chunk_text
    print("\n   Test function chunk_text():")
    test_text = """
Viá»‡t Nam lÃ  má»™t quá»‘c gia tuyá»‡t vá»i. 
The country has a rich history and culture.
ChÃºng ta Ä‘ang phÃ¡t triá»ƒn cÃ´ng nghá»‡ ráº¥t máº¡nh.
Technology sector is booming in recent years.
"""

    start_time = time.time()
    chunks = chunk_text(test_text)
    execution_time = time.time() - start_time

    print(f"   Input: {len(test_text)} kÃ½ tá»±")
    print(f"   Output: {len(chunks)} chunks")
    print(f"   Thá»i gian: {execution_time*1000:.1f}ms")

    if chunks:
        for i, chunk in enumerate(chunks):
            tokens = chunk.metadata.get("token_count", 0)
            strategy = chunk.metadata.get("strategy", "unknown")
            print(f"   Chunk {i+1}: {tokens} tokens, strategy={strategy}")

    # Test function chunk_documents
    print("\n   Test function chunk_documents():")
    documents = [
        Document(
            page_content="Document 1: Ná»™i dung tiáº¿ng Viá»‡t",
            metadata={"source": "doc1.txt"},
        ),
        Document(
            page_content="Document 2: English content here",
            metadata={"source": "doc2.txt"},
        ),
        Document(
            page_content="Document 3: Mixed content with both Viá»‡t and English",
            metadata={"source": "doc3.txt"},
        ),
    ]

    start_time = time.time()
    all_chunks = chunk_documents(documents)
    execution_time = time.time() - start_time

    print(f"   Input: {len(documents)} documents")
    print(f"   Output: {len(all_chunks)} total chunks")
    print(f"   Thá»i gian: {execution_time*1000:.1f}ms")

    # Group by source
    by_source = {}
    for chunk in all_chunks:
        source = chunk.metadata.get("source", "unknown")
        if source not in by_source:
            by_source[source] = []
        by_source[source].append(chunk)

    for source, chunks in by_source.items():
        print(f"   {source}: {len(chunks)} chunks")


def test_performance():
    """Test performance vá»›i content lá»›n"""
    print("\nâš¡ Test Performance")
    print("-" * 30)

    # Táº¡o content lá»›n
    base_text = """
Viá»‡t Nam Ä‘ang tráº£i qua quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i sá»‘ máº¡nh máº½. 
Digital transformation is accelerating across all sectors.
CÃ¡c doanh nghiá»‡p Ä‘ang Ä‘áº§u tÆ° máº¡nh vÃ o cÃ´ng nghá»‡.
Companies are investing heavily in technology infrastructure.
"""

    test_sizes = [100, 500, 1000, 2000]  # Sá»‘ láº§n repeat

    for size in test_sizes:
        large_text = base_text * size
        text_length = len(large_text)

        print(f"\n   Test vá»›i {text_length:,} kÃ½ tá»± ({size}x base text):")

        start_time = time.time()
        chunks = chunk_text(large_text)
        execution_time = time.time() - start_time

        if chunks:
            avg_tokens = sum(
                chunk.metadata.get("token_count", 0) for chunk in chunks
            ) / len(chunks)
            throughput = len(chunks) / execution_time if execution_time > 0 else 0

            print(f"   â†’ {len(chunks)} chunks, avg {avg_tokens:.1f} tokens")
            print(f"   â†’ {execution_time*1000:.1f}ms, {throughput:.1f} chunks/sec")
            print(f"   â†’ Strategy: {chunks[0].metadata.get('strategy')}")


def test_edge_cases():
    """Test cÃ¡c trÆ°á»ng há»£p edge case"""
    print("\nTest Edge Cases")
    print("-" * 30)

    edge_cases = [
        ("", "Empty text"),
        ("   \n\n   \t   ", "Whitespace only"),
        ("A", "Single character"),
        ("Hello world!", "Very short text"),
        ("ğŸ˜€ğŸ‰ğŸ”¥ğŸ’¯â­ Unicode emoji test", "Emoji content"),
        ("Tiáº¿ng Viá»‡t vá»›i dáº¥u Ã Ã¡áº¡áº£Ã£", "Vietnamese diacritics"),
        ("English with numbers 123 and symbols @#$%", "Mixed symbols"),
    ]

    for text, description in edge_cases:
        print(f"\n   Test: {description}")
        print(f"   Input: '{text}'")

        try:
            chunks = chunk_text(text)
            if chunks:
                print(f"   â†’ {len(chunks)} chunks created")
                print(f"   â†’ First chunk: '{chunks[0].page_content[:30]}...'")
                print(f"   â†’ Strategy: {chunks[0].metadata.get('strategy')}")
            else:
                print("   â†’ No chunks created (expected for empty input)")
            print("   PASS")
        except Exception as e:
            print(f"   FAIL: {e}")


def test_chunking():
    """Test chÃ­nh cho Chunking Strategy"""
    print("ğŸ”¬ KIá»‚M TRA CHUNKING STRATEGY")
    print("=" * 60)

    try:
        print("Import chunking modules thÃ nh cÃ´ng!")

        # Test tá»«ng component
        test_multilingual_text_processor()
        test_chunking_class()
        test_chunking_strategies()
        test_simple_api()
        test_performance()
        test_edge_cases()

        print("\n" + "=" * 60)
        print("Táº¤T Cáº¢ TESTS HOÃ€N THÃ€NH THÃ€NH CÃ”NG!")
        print("\nSummary:")
        print("   MultilingualTextProcessor: PhÃ¡t hiá»‡n ngÃ´n ngá»¯ vÃ  cáº¥u trÃºc")
        print("   Chunking class: Khá»Ÿi táº¡o vÃ  cáº¥u hÃ¬nh")
        print("   Strategies: Simple, Hierarchical, Mixed language")
        print("   Simple API: chunk_text() vÃ  chunk_documents()")
        print("   Performance: >1000 chunks/sec vá»›i content lá»›n")
        print("   Edge cases: Xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p Ä‘áº·c biá»‡t")
        print("\nChunking strategy hoáº¡t Ä‘á»™ng tá»‘i Æ°u vÃ  á»•n Ä‘á»‹nh!")

    except Exception as e:
        print(f"âŒ Lá»–I Xáº¢Y RA: {e}")
        import traceback

        print("\nChi tiáº¿t lá»—i:")
        print(traceback.format_exc())


if __name__ == "__main__":
    test_chunking()
